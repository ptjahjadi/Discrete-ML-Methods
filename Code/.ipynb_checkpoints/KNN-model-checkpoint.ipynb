{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def preprocess(filename):\n",
    "    f = open(filename, 'r')\n",
    "    data_table = {}\n",
    "    data_table[\"data\"] = [];\n",
    "    data_table[\"target\"] = [];\n",
    "    for line in f.readlines():\n",
    "        data = line.strip().split(\",\")\n",
    "        attribute_values = data[1:-1]\n",
    "        class_values = data[-1]\n",
    "        data_table[\"data\"].append(attribute_values)\n",
    "        data_table[\"target\"].append(class_values)\n",
    "    \n",
    "    data_table[\"data\"] = np.array(data_table[\"data\"]).astype(np.float)\n",
    "    return data_table\n",
    "\n",
    "class StackingClassifier():\n",
    "\n",
    "    def __init__(self, classifiers, metaclassifier):\n",
    "        self.classifiers = classifiers\n",
    "        self.metaclassifier = metaclassifier\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for clf in self.classifiers:\n",
    "            clf.fit(X, y)\n",
    "        X_meta = self._predict_base(X)\n",
    "        self.metaclassifier.fit(X_meta, y)\n",
    "    \n",
    "    def _predict_base(self, X):\n",
    "        yhats = []\n",
    "        for clf in self.classifiers:\n",
    "            yhat = clf.predict_proba(X)\n",
    "            yhats.append(yhat)\n",
    "        yhats = np.concatenate(yhats, axis=1)\n",
    "        #print(yhats.shape)\n",
    "        assert yhats.shape[0] == X.shape[0]\n",
    "        return yhats\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_meta = self._predict_base(X)\n",
    "        yhat = self.metaclassifier.predict(X_meta)\n",
    "        return yhat\n",
    "    def score(self, X, y):\n",
    "        yhat = self.predict(X)\n",
    "        return accuracy_score(y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "top10 = preprocess(\"../2019S1-proj2-data/train-top10.csv\");\n",
    "top10val = preprocess(\"../2019S1-proj2-data/dev-top10.csv\");\n",
    "X10 = top10[\"data\"]\n",
    "y10 = top10[\"target\"]\n",
    "X10val = top10val[\"data\"]\n",
    "y10val = top10val[\"target\"]\n",
    "\n",
    "top50 = preprocess(\"../2019S1-proj2-data/train-top50.csv\");\n",
    "top50val = preprocess(\"../2019S1-proj2-data/dev-top50.csv\");\n",
    "X50 = top50[\"data\"]\n",
    "y50 = top50[\"target\"]\n",
    "X50val = top50val[\"data\"]\n",
    "y50val = top50val[\"target\"]\n",
    "\n",
    "top100 = preprocess(\"../2019S1-proj2-data/train-top100.csv\");\n",
    "top100val = preprocess(\"../2019S1-proj2-data/dev-top100.csv\");\n",
    "X100 = top100[\"data\"]\n",
    "y100 = top100[\"target\"]\n",
    "X100val = top100val[\"data\"]\n",
    "y100val = top100val[\"target\"]\n",
    "\n",
    "data.append((X10,y10,X10val,y10val));\n",
    "data.append((X50,y50,X50val,y50val));\n",
    "data.append((X100,y100,X100val,y100val));\n",
    "\n",
    "top10proc = preprocess(\"../preprocessed/top10train.csv\");\n",
    "top10valproc = preprocess(\"../preprocessed/top10dev.csv\");\n",
    "X10proc = top10proc[\"data\"]\n",
    "y10proc = top10proc[\"target\"]\n",
    "X10valproc = top10valproc[\"data\"]\n",
    "y10valproc = top10valproc[\"target\"]\n",
    "\n",
    "top50proc = preprocess(\"../preprocessed/top50train.csv\");\n",
    "top50valproc = preprocess(\"../preprocessed/top50dev.csv\");\n",
    "X50proc = top50proc[\"data\"]\n",
    "y50proc = top50proc[\"target\"]\n",
    "X50valproc = top50valproc[\"data\"]\n",
    "y50valproc = top50valproc[\"target\"]\n",
    "\n",
    "top100proc = preprocess(\"../preprocessed/top100train.csv\");\n",
    "top100valproc = preprocess(\"../preprocessed/top100dev.csv\");\n",
    "X100proc = top100proc[\"data\"]\n",
    "y100proc = top100proc[\"target\"]\n",
    "X100valproc = top100valproc[\"data\"]\n",
    "y100valproc = top100valproc[\"target\"]\n",
    "\n",
    "data.append((X10proc,y10proc,X10valproc,y10valproc));\n",
    "data.append((X50proc,y50proc,X50valproc,y50valproc));\n",
    "data.append((X100proc,y100proc,X100valproc,y100valproc));\n",
    "\n",
    "dataTitles = ['Top10',\n",
    "              'Top50',\n",
    "              'Top100',\n",
    "              'Top10proc',\n",
    "              'Top50proc',\n",
    "              'Top100proc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Top10\n",
      "Time elapsed: 1346.61643242836\n",
      "1-Nearest Neighbour : Training Acc 0.282651600170272 ; Validation Acc 0.2879997856147497\n",
      "5-Nearest Neighbour : Training Acc 0.2916973027359622 ; Validation Acc 0.2953960767499196\n",
      "\n",
      "For Top50\n",
      "Time elapsed: 7286.453837156296\n",
      "1-Nearest Neighbour : Training Acc 0.31150110289849464 ; Validation Acc 0.29097438096258976\n",
      "5-Nearest Neighbour : Training Acc 0.32045973453039744 ; Validation Acc 0.30088969878872335\n",
      "\n",
      "For Top100\n",
      "Time elapsed: 13718.756433725357\n",
      "1-Nearest Neighbour : Training Acc 0.32886691691498005 ; Validation Acc 0.2965751956265409\n",
      "5-Nearest Neighbour : Training Acc 0.3384834178243876 ; Validation Acc 0.3061689355772323\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "KNN Models (model that will took considerably long time to run ~30 min)\n",
    "\"\"\"\n",
    "models = [KNeighborsClassifier(n_neighbors=1),\n",
    "          KNeighborsClassifier(n_neighbors=5)]\n",
    "titles = ['1-Nearest Neighbour',\n",
    "          '5-Nearest Neighbour']\n",
    "\n",
    "for ((X,y,Xval,yval),dataTitle) in zip(data,dataTitles):\n",
    "    # timer on\n",
    "    start = time.time()\n",
    "    print(\"For\",dataTitle);\n",
    "\n",
    "    title_training_acc = {}\n",
    "    title_validation_acc = {}\n",
    "    for title, model in zip(titles, models):\n",
    "        model.fit(X, y)\n",
    "        title_training_acc[title] = model.score(X, y)\n",
    "        title_validation_acc[title] = model.score(Xval, yval)\n",
    "    \n",
    "    end = time.time()\n",
    "    print('Time elapsed:',end - start);\n",
    "\n",
    "    for title in titles:\n",
    "        print(title, ': Training Acc', title_training_acc[title], '; Validation Acc', title_validation_acc[title])\n",
    "    \n",
    "    print(\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Top10\n",
      "Time elapsed: 2.6967573165893555\n",
      "1-R : Training Acc 0.2581653186796177 ; Validation Acc 0.2625147389859578\n",
      "Decision Tree depth 5 : Training Acc 0.2767017530281336 ; Validation Acc 0.283738878765141\n",
      "Decision Tree depth 10 : Training Acc 0.2840834333036647 ; Validation Acc 0.28781219852074175\n",
      "Decision Tree : Training Acc 0.2932839286405325 ; Validation Acc 0.2948333154678958\n",
      "\n",
      "For Top50\n",
      "Time elapsed: 31.114784002304077\n",
      "1-R : Training Acc 0.2581653186796177 ; Validation Acc 0.2625147389859578\n",
      "Decision Tree depth 5 : Training Acc 0.27672110212453077 ; Validation Acc 0.283738878765141\n",
      "Decision Tree depth 10 : Training Acc 0.2842382260748423 ; Validation Acc 0.287597813270447\n",
      "Decision Tree : Training Acc 0.33005688634340774 ; Validation Acc 0.30056812091328117\n",
      "\n",
      "For Top100\n",
      "Time elapsed: 84.6716206073761\n",
      "1-R : Training Acc 0.2581653186796177 ; Validation Acc 0.2625147389859578\n",
      "Decision Tree depth 5 : Training Acc 0.276740451220928 ; Validation Acc 0.283738878765141\n",
      "Decision Tree depth 10 : Training Acc 0.28431562246043107 ; Validation Acc 0.28775860220816807\n",
      "Decision Tree : Training Acc 0.35039278665686313 ; Validation Acc 0.3101350627076857\n",
      "\n",
      "For Top10proc\n",
      "Time elapsed: 2.0568695068359375\n",
      "1-R : Training Acc 0.26497620061143146 ; Validation Acc 0.2698038374959803\n",
      "Decision Tree depth 5 : Training Acc 0.2930807631283619 ; Validation Acc 0.3086611641119091\n",
      "Decision Tree depth 10 : Training Acc 0.29831469370380403 ; Validation Acc 0.3093579161753671\n",
      "Decision Tree : Training Acc 0.30800859099880035 ; Validation Acc 0.31951441740808234\n",
      "\n",
      "For Top50proc\n",
      "Time elapsed: 25.9715096950531\n",
      "1-R : Training Acc 0.26497620061143146 ; Validation Acc 0.2698038374959803\n",
      "Decision Tree depth 5 : Training Acc 0.29364188692388066 ; Validation Acc 0.3084735770179012\n",
      "Decision Tree depth 10 : Training Acc 0.2990306102705004 ; Validation Acc 0.3092239253939329\n",
      "Decision Tree : Training Acc 0.3368677682752215 ; Validation Acc 0.3203451602529746\n",
      "\n",
      "For Top100proc\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Decision Tree\n",
    "\"\"\"\n",
    "\n",
    "models = [DecisionTreeClassifier(max_depth=1),\n",
    "          DecisionTreeClassifier(max_depth=5),\n",
    "          DecisionTreeClassifier(max_depth=10),\n",
    "          DecisionTreeClassifier(max_depth=None)]\n",
    "\n",
    "titles = ['1-R',\n",
    "          'Decision Tree depth 5',\n",
    "          'Decision Tree depth 10',\n",
    "          'Decision Tree']\n",
    "\n",
    "for ((X,y,Xval,yval),dataTitle) in zip(data,dataTitles):\n",
    "    # timer on\n",
    "    start = time.time()\n",
    "    print(\"For\",dataTitle);\n",
    "\n",
    "    title_training_acc = {}\n",
    "    title_validation_acc = {}\n",
    "    for title, model in zip(titles, models):\n",
    "        model.fit(X, y)\n",
    "        title_training_acc[title] = model.score(X, y)\n",
    "        title_validation_acc[title] = model.score(Xval, yval)\n",
    "    \n",
    "    end = time.time()\n",
    "    print('Time elapsed:',end - start);\n",
    "\n",
    "    for title in titles:\n",
    "        print(title, ': Training Acc', title_training_acc[title], '; Validation Acc', title_validation_acc[title])\n",
    "    \n",
    "    print(\"\");\n",
    "\n",
    "# title_crossvalidation_acc = {}\n",
    "# for title, model in zip(titles, models):\n",
    "#     title_crossvalidation_acc[title] = np.mean(cross_val_score(model, X, y, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Top10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patpa\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 2.6655423641204834\n",
      "Gaussian Naive Bayes : Training Acc 0.29154250996478465 ; Validation Acc 0.29480651731160895\n",
      "Multinomial Naive Bayes laplace smoothing : Training Acc 0.29132966990441544 ; Validation Acc 0.29491370993675636\n",
      "Multinomial Naive Bayes 0.5 smoothing : Training Acc 0.29132966990441544 ; Validation Acc 0.29491370993675636\n",
      "Multinomial Naive Bayes no smoothing : Training Acc 0.29132966990441544 ; Validation Acc 0.29491370993675636\n",
      "Binomial Naive Bayes : Training Acc 0.29136836809720984 ; Validation Acc 0.2948333154678958\n",
      "\n",
      "For Top50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patpa\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 5.644241809844971\n",
      "Gaussian Naive Bayes : Training Acc 0.3197728416082969 ; Validation Acc 0.29842426841033337\n",
      "Multinomial Naive Bayes laplace smoothing : Training Acc 0.3195793506443249 ; Validation Acc 0.30134526744559975\n",
      "Multinomial Naive Bayes 0.5 smoothing : Training Acc 0.3195890251925235 ; Validation Acc 0.30137206560188656\n",
      "Multinomial Naive Bayes no smoothing : Training Acc 0.3195890251925235 ; Validation Acc 0.30134526744559975\n",
      "Binomial Naive Bayes : Training Acc 0.3206919236871638 ; Validation Acc 0.3007021116947154\n",
      "\n",
      "For Top100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patpa\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 9.311599254608154\n",
      "Gaussian Naive Bayes : Training Acc 0.3355520297202121 ; Validation Acc 0.3014524600707471\n",
      "Multinomial Naive Bayes laplace smoothing : Training Acc 0.33679037188963273 ; Validation Acc 0.3078304212670168\n",
      "Multinomial Naive Bayes 0.5 smoothing : Training Acc 0.33679037188963273 ; Validation Acc 0.3078840175795905\n",
      "Multinomial Naive Bayes no smoothing : Training Acc 0.3367806973414342 ; Validation Acc 0.3078840175795905\n",
      "Binomial Naive Bayes : Training Acc 0.33762238303471226 ; Validation Acc 0.3070264765784114\n",
      "\n",
      "For Top10proc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patpa\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 2.4691522121429443\n",
      "Gaussian Naive Bayes : Training Acc 0.28697612321504584 ; Validation Acc 0.28746382248901275\n",
      "Multinomial Naive Bayes laplace smoothing : Training Acc 0.3045354281955033 ; Validation Acc 0.3154946939650552\n",
      "Multinomial Naive Bayes 0.5 smoothing : Training Acc 0.3045354281955033 ; Validation Acc 0.3154946939650552\n",
      "Multinomial Naive Bayes no smoothing : Training Acc 0.3045451027437019 ; Validation Acc 0.31552149212134206\n",
      "Binomial Naive Bayes : Training Acc 0.3044290081653187 ; Validation Acc 0.31525351055847356\n",
      "\n",
      "For Top50proc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patpa\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 5.637939214706421\n",
      "Gaussian Naive Bayes : Training Acc 0.31868929221005377 ; Validation Acc 0.2922338943080716\n",
      "Multinomial Naive Bayes laplace smoothing : Training Acc 0.3255291977864634 ; Validation Acc 0.31691499624825814\n",
      "Multinomial Naive Bayes 0.5 smoothing : Training Acc 0.3255775705274564 ; Validation Acc 0.31691499624825814\n",
      "Multinomial Naive Bayes no smoothing : Training Acc 0.3255678959792578 ; Validation Acc 0.31691499624825814\n",
      "Binomial Naive Bayes : Training Acc 0.3253744050152858 ; Validation Acc 0.31629863865366065\n",
      "\n",
      "For Top100proc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patpa\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 38.083194732666016\n",
      "Gaussian Naive Bayes : Training Acc 0.386981927943965 ; Validation Acc 0.28470361239146746\n",
      "Multinomial Naive Bayes laplace smoothing : Training Acc 0.40314809798382417 ; Validation Acc 0.328009432951013\n",
      "Multinomial Naive Bayes 0.5 smoothing : Training Acc 0.4035544290081653 ; Validation Acc 0.327821845857005\n",
      "Multinomial Naive Bayes no smoothing : Training Acc 0.4042219728338687 ; Validation Acc 0.3278486440132919\n",
      "Binomial Naive Bayes : Training Acc 0.4144092720869935 ; Validation Acc 0.3232393611319541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Naive Bayes\n",
    "\"\"\"\n",
    "models = [GaussianNB(),\n",
    "          MultinomialNB(alpha=1.0),\n",
    "          MultinomialNB(alpha=0.5),\n",
    "          MultinomialNB(alpha=0),\n",
    "          BernoulliNB()]\n",
    "\n",
    "titles = ['Gaussian Naive Bayes',\n",
    "          'Multinomial Naive Bayes laplace smoothing',\n",
    "          'Multinomial Naive Bayes 0.5 smoothing',\n",
    "          'Multinomial Naive Bayes no smoothing',\n",
    "          'Binomial Naive Bayes']\n",
    "\n",
    "for ((X,y,Xval,yval),dataTitle) in zip(data,dataTitles):\n",
    "    # timer on\n",
    "    start = time.time()\n",
    "    print(\"For\",dataTitle);\n",
    "\n",
    "    title_training_acc = {}\n",
    "    title_validation_acc = {}\n",
    "    for title, model in zip(titles, models):\n",
    "        model.fit(X, y)\n",
    "        title_training_acc[title] = model.score(X, y)\n",
    "        title_validation_acc[title] = model.score(Xval, yval)\n",
    "    \n",
    "    end = time.time()\n",
    "    print('Time elapsed:',end - start);\n",
    "\n",
    "    for title in titles:\n",
    "        print(title, ': Training Acc', title_training_acc[title], '; Validation Acc', title_validation_acc[title])\n",
    "    \n",
    "    print(\"\");\n",
    "        \n",
    "# title_crossvalidation_acc = {}\n",
    "# for title, model in zip(titles, models):\n",
    "#     title_crossvalidation_acc[title] = np.mean(cross_val_score(model, X, y, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Top10\n",
      "Time elapsed: 37.535595417022705\n",
      "Multinomial Naive Bayes laplace smoothing : Training Acc 0.29007197863859757 ; Validation Acc 0.2930110408403902\n",
      "ADA MNB : Training Acc 0.29149413722379164 ; Validation Acc 0.29464572837388786\n",
      "\n",
      "For Top50\n",
      "Time elapsed: 49.62624979019165\n",
      "Multinomial Naive Bayes laplace smoothing : Training Acc 0.3198599125420843 ; Validation Acc 0.2985582591917676\n",
      "ADA MNB : Training Acc 0.32021787082543246 ; Validation Acc 0.3001929467252653\n",
      "\n",
      "For Top100\n",
      "Time elapsed: 68.94897079467773\n",
      "Multinomial Naive Bayes laplace smoothing : Training Acc 0.32501644673193764 ; Validation Acc 0.3038910922928503\n",
      "ADA MNB : Training Acc 0.3350973259548779 ; Validation Acc 0.3061689355772323\n",
      "\n",
      "For Top10proc\n",
      "Time elapsed: 37.345722913742065\n",
      "Multinomial Naive Bayes laplace smoothing : Training Acc 0.28488642080414844 ; Validation Acc 0.2939489763104298\n",
      "ADA MNB : Training Acc 0.2907008242715065 ; Validation Acc 0.2935202058098403\n",
      "\n",
      "For Top50proc\n",
      "Time elapsed: 49.13231420516968\n",
      "Multinomial Naive Bayes laplace smoothing : Training Acc 0.31980186525289267 ; Validation Acc 0.303757101511416\n",
      "ADA MNB : Training Acc 0.32457141751480206 ; Validation Acc 0.2982098831600386\n",
      "\n",
      "For Top100proc\n",
      "Time elapsed: 106.918860912323\n",
      "Multinomial Naive Bayes laplace smoothing : Training Acc 0.3562749119616114 ; Validation Acc 0.31495873083931825\n",
      "ADA MNB : Training Acc 0.36242792461592044 ; Validation Acc 0.30440025726230036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multiNBbagging = BaggingClassifier(base_estimator= MultinomialNB(), max_samples = 0.35, max_features = 0.9)\n",
    "adaMNB = AdaBoostClassifier(base_estimator=MultinomialNB(), n_estimators=100)\n",
    "\n",
    "models = [multiNBbagging, adaMNB]\n",
    "\n",
    "titles = ['Multinomial Naive Bayes laplace smoothing', 'ADA MNB']\n",
    "\n",
    "\n",
    "for ((X,y,Xval,yval),dataTitle) in zip(data,dataTitles):\n",
    "    # timer on\n",
    "    start = time.time()\n",
    "    print(\"For\",dataTitle);\n",
    "    \n",
    "    title_training_acc = {}\n",
    "    title_validation_acc = {}\n",
    "    for title, model in zip(titles, models):\n",
    "        model.fit(X, y)\n",
    "        title_training_acc[title] = model.score(X, y)\n",
    "        title_validation_acc[title] = model.score(Xval, yval)\n",
    "    \n",
    "    end = time.time()\n",
    "    print('Time elapsed:',end - start);\n",
    "\n",
    "    for title in titles:\n",
    "        print(title, ': Training Acc', title_training_acc[title], '; Validation Acc', title_validation_acc[title])\n",
    "    \n",
    "    print(\"\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Top10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maurice/Documents/ML/Machine_Learning/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/maurice/Documents/ML/Machine_Learning/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/maurice/Documents/ML/Machine_Learning/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 34.51904821395874\n",
      "RF & B MNB Stacker : Training Acc 0.29318718315854647 ; Validation Acc 0.2945921320613142\n",
      "B MNB & A MNB Stacker : Training Acc 0.29129097171162105 ; Validation Acc 0.29486011362418263\n",
      "\n",
      "For Top50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maurice/Documents/ML/Machine_Learning/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/maurice/Documents/ML/Machine_Learning/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 70.84763383865356\n",
      "RF & B MNB Stacker : Training Acc 0.32977632444564836 ; Validation Acc 0.29858505734805446\n",
      "B MNB & A MNB Stacker : Training Acc 0.3173638791068457 ; Validation Acc 0.29858505734805446\n",
      "\n",
      "For Top100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maurice/Documents/ML/Machine_Learning/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/maurice/Documents/ML/Machine_Learning/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 127.01181626319885\n",
      "RF & B MNB Stacker : Training Acc 0.3497542664757556 ; Validation Acc 0.3037035051988423\n",
      "B MNB & A MNB Stacker : Training Acc 0.33639371541349017 ; Validation Acc 0.303757101511416\n",
      "\n",
      "For Top10proc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maurice/Documents/ML/Machine_Learning/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/maurice/Documents/ML/Machine_Learning/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 34.05537700653076\n",
      "RF & B MNB Stacker : Training Acc 0.2929646685499787 ; Validation Acc 0.3020420195090578\n",
      "B MNB & A MNB Stacker : Training Acc 0.2921713555976936 ; Validation Acc 0.29772751634687533\n",
      "\n",
      "For Top50proc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maurice/Documents/ML/Machine_Learning/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/maurice/Documents/ML/Machine_Learning/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 68.29262471199036\n",
      "RF & B MNB Stacker : Training Acc 0.32822839673387255 ; Validation Acc 0.2986922499732018\n",
      "B MNB & A MNB Stacker : Training Acc 0.3247939321233698 ; Validation Acc 0.29799549790974383\n",
      "\n",
      "For Top100proc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maurice/Documents/ML/Machine_Learning/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/maurice/Documents/ML/Machine_Learning/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 239.94615721702576\n",
      "RF & B MNB Stacker : Training Acc 0.3849986455632522 ; Validation Acc 0.308500375174188\n",
      "B MNB & A MNB Stacker : Training Acc 0.3685035408846407 ; Validation Acc 0.30943831064422767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Stacking Classifier\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "\n",
    "multiNBbagging = BaggingClassifier(base_estimator= MultinomialNB(), max_samples = 0.5, max_features = 1.0)\n",
    "adaMNB = AdaBoostClassifier(base_estimator=MultinomialNB())\n",
    "\n",
    "classifiers = [RandomForestClassifier(),\n",
    "               multiNBbagging]\n",
    "\n",
    "meta_classifier = LogisticRegression(solver=\"saga\")\n",
    "\n",
    "RFMNBstacker = StackingClassifier(classifiers, meta_classifier)\n",
    "\n",
    "classifiers = [adaMNB,\n",
    "               multiNBbagging]\n",
    "\n",
    "meta_classifier = LogisticRegression(solver=\"saga\")\n",
    "\n",
    "BMNBAMNBstacker = StackingClassifier(classifiers, meta_classifier)\n",
    "\n",
    "models = [RFMNBstacker,\n",
    "          BMNBAMNBstacker]\n",
    "\n",
    "titles = ['RF & B MNB Stacker',\n",
    "          'B MNB & A MNB Stacker']\n",
    "\n",
    "\n",
    "for ((X,y,Xval,yval),dataTitle) in zip(data,dataTitles):\n",
    "    # timer on\n",
    "    start = time.time()\n",
    "    print(\"For\",dataTitle);\n",
    "\n",
    "    title_training_acc = {}\n",
    "    title_validation_acc = {}\n",
    "    for title, model in zip(titles, models):\n",
    "        model.fit(X, y)\n",
    "        title_training_acc[title] = model.score(X, y)\n",
    "        title_validation_acc[title] = model.score(Xval, yval)\n",
    "    \n",
    "    end = time.time()\n",
    "    print('Time elapsed:',end - start);\n",
    "\n",
    "    for title in titles:\n",
    "        print(title, ': Training Acc', title_training_acc[title], '; Validation Acc', title_validation_acc[title])\n",
    "    \n",
    "    print(\"\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Preprocess the test data\n",
    "\"\"\"\n",
    "\n",
    "top100testproc = preprocess(\"../preprocessed/top100test.csv\");\n",
    "X100testproc = top100testproc[\"data\"]\n",
    "y100testproc = top100testproc[\"target\"]\n",
    "top10testproc = preprocess(\"../preprocessed/top10test.csv\");\n",
    "X10testproc = top10testproc[\"data\"]\n",
    "y10testproc = top10testproc[\"target\"]\n",
    "top50testproc = preprocess(\"../preprocessed/top50test.csv\");\n",
    "X50testproc = top50testproc[\"data\"]\n",
    "y50testproc = top50testproc[\"target\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X100proc\n",
    "X100valproc\n",
    "y100proc\n",
    "y100valproc\n",
    "ultimateX = []\n",
    "ultimatey = []\n",
    "\n",
    "for i in X100proc:\n",
    "    ultimateX.append(i)\n",
    "for i in X100valproc:\n",
    "    ultimateX.append(i)\n",
    "for i in y100proc:\n",
    "    ultimatey.append(i)\n",
    "for i in y100valproc:\n",
    "    ultimatey.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33052845964197664"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Choose the best model to use for submission\n",
    "\"\"\"\n",
    "\n",
    "multiNBbagging = BaggingClassifier(base_estimator= MultinomialNB(), max_samples = 0.35, max_features = 0.9, warm_start=True)\n",
    "\n",
    "# classifiers = [RandomForestClassifier(),\n",
    "#                multiNBbagging]\n",
    "\n",
    "# meta_classifier = LogisticRegression(solver=\"saga\")\n",
    "\n",
    "# classifiers = [adaMNB,\n",
    "#                multiNBbagging]\n",
    "\n",
    "# meta_classifier = LogisticRegression(solver=\"saga\")\n",
    "\n",
    "\n",
    "# clf.fit(data_transformed, digits.target)\n",
    "\n",
    "# model = LogisticRegression(penalty='elasticnet', solver='saga', multi_class='multinomial', max_iter=100, warm_start=True)\n",
    "\n",
    "model = multiNBbagging\n",
    "\n",
    "model.fit(X100proc,y100proc)\n",
    "\n",
    "model.score(X100valproc, y100valproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Make the submission csv based on the best model\n",
    "\"\"\"\n",
    "\n",
    "header = ['Id','Class']\n",
    "\n",
    "predictionArray = model.predict(X100testproc)\n",
    "len(predictionArray)\n",
    "with open('../submission.csv',\"w+\") as file:\n",
    "    line = \"{},{}\".format(header[0],header[1])\n",
    "    file.write(line)\n",
    "    file.write('\\n')\n",
    "    \n",
    "\n",
    "    index = 1\n",
    "    for prediction in predictionArray:\n",
    "        line = \"3{},{}\".format(index, prediction)\n",
    "        file.write(line)\n",
    "        file.write('\\n')\n",
    "        index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
